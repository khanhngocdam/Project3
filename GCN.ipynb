{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232187 entries, 0 to 232186\n",
      "Data columns (total 85 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   FlowID                   232183 non-null  object \n",
      " 1   SourceIP                 232187 non-null  object \n",
      " 2   SourcePort               232187 non-null  float64\n",
      " 3   DestinationIP            232187 non-null  object \n",
      " 4   DestinationPort          232187 non-null  float64\n",
      " 5   Protocol                 232187 non-null  float64\n",
      " 6   Timestamp                232187 non-null  object \n",
      " 7   FlowDuration             232187 non-null  float64\n",
      " 8   TotalFwdPackets          232187 non-null  float64\n",
      " 9   TotalBackwardPackets     232187 non-null  float64\n",
      " 10  TotalLengthofFwdPackets  232187 non-null  float64\n",
      " 11  TotalLengthofBwdPackets  232187 non-null  float64\n",
      " 12  FwdPacketLengthMax       232187 non-null  float64\n",
      " 13  FwdPacketLengthMin       232187 non-null  float64\n",
      " 14  FwdPacketLengthMean      232187 non-null  float64\n",
      " 15  FwdPacketLengthStd       232187 non-null  float64\n",
      " 16  BwdPacketLengthMax       232187 non-null  float64\n",
      " 17  BwdPacketLengthMin       232187 non-null  float64\n",
      " 18  BwdPacketLengthMean      232187 non-null  float64\n",
      " 19  BwdPacketLengthStd       232187 non-null  float64\n",
      " 20  FlowBytes/s              232187 non-null  float64\n",
      " 21  FlowPackets/s            232187 non-null  float64\n",
      " 22  FlowIATMean              232186 non-null  float64\n",
      " 23  FlowIATStd               232186 non-null  float64\n",
      " 24  FlowIATMax               232186 non-null  float64\n",
      " 25  FlowIATMin               232186 non-null  float64\n",
      " 26  FwdIATTotal              232186 non-null  float64\n",
      " 27  FwdIATMean               232186 non-null  float64\n",
      " 28  FwdIATStd                232186 non-null  float64\n",
      " 29  FwdIATMax                232186 non-null  float64\n",
      " 30  FwdIATMin                232186 non-null  float64\n",
      " 31  BwdIATTotal              232186 non-null  float64\n",
      " 32  BwdIATMean               232186 non-null  float64\n",
      " 33  BwdIATStd                232186 non-null  float64\n",
      " 34  BwdIATMax                232185 non-null  float64\n",
      " 35  BwdIATMin                232185 non-null  float64\n",
      " 36  FwdPSHFlags              232185 non-null  float64\n",
      " 37  BwdPSHFlags              232185 non-null  float64\n",
      " 38  FwdURGFlags              232185 non-null  float64\n",
      " 39  BwdURGFlags              232185 non-null  float64\n",
      " 40  FwdHeaderLength          232185 non-null  float64\n",
      " 41  BwdHeaderLength          232185 non-null  float64\n",
      " 42  FwdPackets/s             232185 non-null  float64\n",
      " 43  BwdPackets/s             232184 non-null  float64\n",
      " 44  MinPacketLength          232184 non-null  float64\n",
      " 45  MaxPacketLength          232184 non-null  float64\n",
      " 46  PacketLengthMean         232184 non-null  float64\n",
      " 47  PacketLengthStd          232184 non-null  object \n",
      " 48  PacketLengthVariance     232183 non-null  float64\n",
      " 49  FINFlagCount             232183 non-null  float64\n",
      " 50  SYNFlagCount             232183 non-null  float64\n",
      " 51  RSTFlagCount             232183 non-null  float64\n",
      " 52  PSHFlagCount             232183 non-null  float64\n",
      " 53  ACKFlagCount             232183 non-null  float64\n",
      " 54  URGFlagCount             232183 non-null  float64\n",
      " 55  CWEFlagCount             232183 non-null  object \n",
      " 56  ECEFlagCount             232182 non-null  float64\n",
      " 57  Down/UpRatio             232182 non-null  object \n",
      " 58  AveragePacketSize        232181 non-null  float64\n",
      " 59  AvgFwdSegmentSize        232181 non-null  float64\n",
      " 60  AvgBwdSegmentSize        232181 non-null  float64\n",
      " 61  FwdHeaderLength.1        232181 non-null  float64\n",
      " 62  FwdAvgBytes/Bulk         232181 non-null  float64\n",
      " 63  FwdAvgPackets/Bulk       232181 non-null  float64\n",
      " 64  FwdAvgBulkRate           232181 non-null  float64\n",
      " 65  BwdAvgBytes/Bulk         232181 non-null  float64\n",
      " 66  BwdAvgPackets/Bulk       232181 non-null  float64\n",
      " 67  BwdAvgBulkRate           232181 non-null  float64\n",
      " 68  SubflowFwdPackets        232181 non-null  float64\n",
      " 69  SubflowFwdBytes          232181 non-null  float64\n",
      " 70  SubflowBwdPackets        232181 non-null  float64\n",
      " 71  SubflowBwdBytes          232181 non-null  float64\n",
      " 72  Init_Win_bytes_forward   232181 non-null  float64\n",
      " 73  Init_Win_bytes_backward  232181 non-null  float64\n",
      " 74  act_data_pkt_fwd         232181 non-null  float64\n",
      " 75  min_seg_size_forward     232181 non-null  float64\n",
      " 76  ActiveMean               232181 non-null  float64\n",
      " 77  ActiveStd                232180 non-null  float64\n",
      " 78  ActiveMax                232180 non-null  float64\n",
      " 79  ActiveMin                232180 non-null  float64\n",
      " 80  IdleMean                 232180 non-null  float64\n",
      " 81  IdleStd                  232180 non-null  float64\n",
      " 82  IdleMax                  232180 non-null  float64\n",
      " 83  IdleMin                  232180 non-null  float64\n",
      " 84  Label                    232187 non-null  int64  \n",
      "dtypes: float64(77), int64(1), object(7)\n",
      "memory usage: 150.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến folder chứa các file CSV\n",
    "list_folder_malware = ['./CSVS/SMSmalware-CSVs/SMSmalware/Biige', './CSVS/SMSmalware-CSVs/SMSmalware/Fakeinst', './CSVS/SMSmalware-CSVs/SMSmalware/FakeNotify',\n",
    "                       './CSVS/SMSmalware-CSVs/SMSmalware/Mazarbot', './CSVS/SMSmalware-CSVs/SMSmalware/Jifake', './CSVS/SMSmalware-CSVs/SMSmalware/Nandrobox']\n",
    "                     #   './CSVS/SMSmalware-CSVs/SMSmalware/Plankton', './CSVS/SMSmalware-CSVs/SMSmalware/Zsone']\n",
    "\n",
    "list_folder_benign = ['./CSVS/Benign-CSVs/Benign/Benign2017']\n",
    "\n",
    "# Tạo một DataFrame để chứa dữ liệu từ tất cả các file CSV\n",
    "list_df = []\n",
    "all_data = pd.DataFrame()\n",
    "#Đọc từng file CSV và nối dữ liệu vào DataFrame chung\n",
    "# Đọc benign\n",
    "i = 0\n",
    "for folder in list_folder_benign: \n",
    "     file_list =  os.listdir(folder)\n",
    "     csv_files = [file for file in file_list if file.endswith('.csv')]\n",
    "     for csv in csv_files: \n",
    "            if i < 150: \n",
    "               file_path = os.path.join(folder, csv)\n",
    "               data = pd.read_csv(file_path, header=0)\n",
    "               data.columns = data.columns.str.replace(' ', '')\n",
    "               data = data.sort_values(by='Timestamp')\n",
    "               data['Label'] = 1\n",
    "               list_df.append(data)\n",
    "               all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "               i = i + 1\n",
    "# Đọc malware\n",
    "for folder in list_folder_malware: \n",
    "     file_list =  os.listdir(folder)\n",
    "     csv_files = [file for file in file_list if file.endswith('.csv')]\n",
    "     for csv in csv_files: \n",
    "        file_path = os.path.join(folder, csv)\n",
    "        data = pd.read_csv(file_path, header=0)\n",
    "        data.columns = data.columns.str.replace(' ', '')\n",
    "        data = data.sort_values(by='Timestamp')\n",
    "        data['Label'] = 0\n",
    "        list_df.append(data)\n",
    "        all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hiển thị DataFrame chứa dữ liệu từ tất cả các file CSV\n",
    "print(all_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    131617\n",
       "1    100570\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label                      1.000000\n",
       "ACKFlagCount               0.021929\n",
       "URGFlagCount               0.018869\n",
       "Init_Win_bytes_backward    0.014388\n",
       "FINFlagCount               0.009952\n",
       "                             ...   \n",
       "FwdIATStd                 -0.056582\n",
       "FlowIATMax                -0.061562\n",
       "FlowDuration              -0.063843\n",
       "FwdIATTotal               -0.071185\n",
       "FwdIATMax                 -0.074151\n",
       "Name: Label, Length: 65, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_drop=['FlowID', 'SourceIP', 'DestinationIP', 'SourcePort', 'DestinationPort', 'Timestamp',\n",
    "                               'PacketLengthStd', 'CWEFlagCount', 'Down/UpRatio','FwdAvgPackets/Bulk', 'FwdAvgBulkRate', \n",
    "                               'BwdAvgBytes/Bulk', 'BwdAvgPackets/Bulk', 'BwdAvgBulkRate', 'FwdURGFlags', 'BwdURGFlags', \n",
    "                               'RSTFlagCount', 'ECEFlagCount', 'BwdPSHFlags', 'FwdAvgBytes/Bulk']\n",
    "# Tính ma trận tương quan\n",
    "data = all_data.drop(columns=columns_drop)\n",
    "corr_matrix = data.corr()\n",
    "corr_matrix['Label'].sort_values(ascending=False)\n",
    "\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to divide each cell's value by 10 until the largest number in the column is <= 10\n",
    "def divide_until_largest_less_than_10(df):\n",
    "    for column in df.columns.tolist():\n",
    "        contains_only_numbers = df[column].apply(lambda x: isinstance(x, (int, float))).all()\n",
    "        if contains_only_numbers:\n",
    "            largest_number = df[column].max()\n",
    "            while largest_number > 10:\n",
    "                df[column] /= 10\n",
    "                largest_number = df[column].max()            \n",
    "    return df\n",
    "\n",
    "# Iterate over each DataFrame in the list\n",
    "for df in list_df:\n",
    "    df_copy = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    df_modified = divide_until_largest_less_than_10(df_copy)\n",
    "    list_df.pop(0)\n",
    "    list_df.append(df_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ip_label(df):\n",
    "    le_columns = ['SourceIP', 'DestinationIP']\n",
    "    ip_list = list(df['SourceIP'].unique()) + list(df['DestinationIP'].unique())\n",
    "    ip_set = list(set(ip_list))\n",
    "\n",
    "    for column in le_columns:\n",
    "        list_unique = list(df[column].unique())\n",
    "        for val in list_unique:\n",
    "            df.loc[df[column] == val, column] = ip_set.index(val)\n",
    "\n",
    "    df['DestinationIP'] = df['DestinationIP'].astype(int)\n",
    "    df['SourceIP'] = df['SourceIP'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "list_graph = []\n",
    "list_label = []\n",
    "for df in list_df:\n",
    "    df = convert_ip_label(df)\n",
    "    graph = nx.from_pandas_edgelist(df, 'SourceIP', 'DestinationIP',\n",
    "                                     create_using=nx.MultiDiGraph(), edge_attr=df.drop(columns=columns_drop).columns.values.tolist())\n",
    "    list_graph.append(graph)\n",
    "    count_value = len(df['Label'].unique())\n",
    "    if count_value == 1: \n",
    "        label = df['Label'].unique()[0]\n",
    "    else: \n",
    "        label = 0\n",
    "    list_label.append(label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def graph_to_pyg_data(graph, label):\n",
    "    # Khởi tạo ma trận B_in với tất cả các phần tử bằng 0\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    num_edges = graph.number_of_edges()\n",
    "    B_in = torch.zeros((num_nodes, num_edges), dtype=torch.float32)\n",
    "    B_out = torch.zeros((num_nodes, num_edges), dtype=torch.float32)\n",
    "    for i, node in enumerate(graph.nodes):\n",
    "        for j, edge in enumerate(graph.edges):\n",
    "            if node == edge[1]:\n",
    "                B_in[i, j] = 1\n",
    "            if node == edge[0]:\n",
    "                B_out[i, j] = 1\n",
    "    Y = torch.tensor(label, dtype=torch.long)\n",
    "    X = torch.tensor([list(graph.edges[edge].values()) for edge in graph.edges], dtype=torch.float)\n",
    "    return Data(B_in=B_in,B_out=B_out, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_graph_labeled = list(zip(list_graph, list_label))\n",
    "list_data = []\n",
    "for graph, label in list_graph_labeled:\n",
    "    list_data.append(graph_to_pyg_data(graph, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "train_data, test_data = train_test_split(list_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "# from torch.utils.data import Dataset\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, list_data):\n",
    "#         self.list_data = list_data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.list_data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         B_in, B_out, X, Y = self.list_data[idx]\n",
    "\n",
    "#         return {B_in, B_out, X, Y}\n",
    "\n",
    "batch_size = 1\n",
    "# DataLoader cho tập dữ liệu đào tạo\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# DataLoader cho tập dữ liệu kiểm thử\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.fc0 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(3*hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(3*hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, B_in, B_out, X):\n",
    "        E_0 = F.relu(self.fc0(X))\n",
    "        matrix1 = torch.matmul(B_in, E_0)\n",
    "        matrix2 = torch.matmul(B_out, E_0)\n",
    "        result_matrix_0 = torch.cat((matrix1, matrix2), dim=1)\n",
    "        H_0 = F.relu(self.fc1(result_matrix_0))\n",
    "        matrix3 = torch.matmul(B_in.t(), H_0)\n",
    "        matrix4 = torch.matmul(B_out.t(), H_0)\n",
    "        result_matrix_1 = torch.cat((matrix3, matrix4, E_0), dim=1)\n",
    "        E_1 = F.relu(self.fc2(result_matrix_1))\n",
    "        matrix5 = torch.matmul(B_in, E_1)\n",
    "        matrix6 = torch.matmul(B_out, E_1)\n",
    "        result_matrix_2 = torch.cat((matrix5, matrix6, H_0), dim=1)\n",
    "        H_1 = F.relu(self.fc3(result_matrix_2))\n",
    "        H_1_mean = torch.mean(H_1, dim=0, keepdim=True)\n",
    "        # output = F.softmax(self.fc4(H_1_mean), dim=1)\n",
    "        output = self.fc4(H_1_mean)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphNeuralNetwork(\n",
      "  (fc0): Linear(in_features=65, out_features=64, bias=True)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=192, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=192, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Adam' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 47\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(output)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# print(f'---train---loss: {loss}')\u001b[39;00m\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Adam' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Định nghĩa mô hình\n",
    "input_dim =  65\n",
    "hidden_dim =  64\n",
    "output_dim =  2\n",
    "model = GraphNeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "print(model)\n",
    "# Xác định hàm loss và trình tối ưu hóa\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.B_in, data.B_out, data.X)\n",
    "        # print(f'---train---output: {output}\\nY: {data.Y}')\n",
    "        if torch.isnan(output).any():\n",
    "            continue\n",
    "        loss = criterion(output, torch.unsqueeze(data.Y, dim=0))\n",
    "        # print(f'---train---loss: {loss}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Đánh giá mô hình\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    for data in loader:\n",
    "        output = model(data.B_in, data.B_out, data.X)\n",
    "        print(f'---eval---output: {output}')\n",
    "        pred = output.argmax(dim=1)\n",
    "        print(f'---eval---pred: {pred}, Y: {data.Y}')\n",
    "        correct += int((pred == data.Y).sum())\n",
    "        total_samples += 1\n",
    "    return correct / total_samples\n",
    "\n",
    "# Huấn luyện và kiểm thử\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    test_accuracy = evaluate(model, test_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
